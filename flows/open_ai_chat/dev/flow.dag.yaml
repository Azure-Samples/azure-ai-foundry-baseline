id: template_chat_flow
name: Template Chat Flow
inputs:
  chat_history:
    type: list
    default:
    - inputs:
        question: Hello
      outputs:
        answer: Hello! How can I assist you today?
    - inputs:
        question: This is a test
      outputs:
        answer: Sure! I'm here to help. What would you like to test?
    - inputs:
        question: Hi there
      outputs:
        answer: Hello! How can I assist you today?
    - inputs:
        question: Is this working?
      outputs:
        answer: Yes, everything seems to be working fine. How can I assist you?
    - inputs:
        question: Hello
      outputs:
        answer: Hello! How can I assist you today?
    is_chat_input: false
    is_chat_history: true
  question:
    type: string
    default: Hello
    is_chat_input: true
outputs:
  answer:
    type: string
    reference: ${chat.output}
    is_chat_output: true
nodes:
- name: chat
  type: llm
  source:
    type: code
    path: chat.jinja2
  inputs:
    deployment_name: gpt-35-turbo-16k
    temperature: 0.7
    top_p: 1
    stop: ""
    max_tokens: 256
    presence_penalty: 0
    frequency_penalty: 0
    logit_bias: ""
    question: ${inputs.question}
    chat_history: ${inputs.chat_history}
  provider: AzureOpenAI
  connection: OpenAIConnection
  api: chat
  module: promptflow.tools.aoai
  use_variants: false
node_variants: {}
environment:
  python_requirements_txt: requirements.txt
